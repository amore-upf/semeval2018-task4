# if main.py is run with option -r, hyperparameter values are randomly sampled.
# * '50-500' means sampling from uniform distribution over interval
# * '0.001~0.1' means sampling from log distribution over interval
# * 'yes|no', 'dot|cos' etc. means sampling from list of discrete options
# Please respect float = 0.0, int = 0 or it crashes :)

[Data]

dataset:       train    # can currently be train or trial or test, referring to the semeval datasets
level:         scene   # can be scene or episode
folds:         5

[Training]

no shuffle:     no
epochs:         50
test every:     1
stop criterion: 5

batch size:     24
chunk size:     200     300-1000        # 1000 is just above longest scene in training data.
learning rate:  0.001   0.0001~0.1
weight decay:   0.0     0.0~0.00001

optimizer:      adam
class weights:  yes      yes|no         # 'yes' to divide loss by sqrt of frequence of class (entity)

[Model]

token emb:      200    100-300      # or comment this and uncomment the next line instead
# token emb:      google_news       # requires file data/GoogleNews-vectors-negative300.bin.gz
speaker emb:    200    100-300

bidirectional:      yes       yes|no
layers lstm:        1                   # multi-layer currently not implemented
hidden lstm 1:      400    300-500

dropout prob 1:  0.0     0.0-0.5
dropout prob 2:  0.0     0.0-0.1
nonlinearity 1:  relu    tanh|relu|no   # Nonlinearity before LSTM
nonlinearity 2:  relu    tanh|relu|no   # Nonlinearity after LSTM

attention lstm:     no	   dot|no|feedforward
attention window:	yes     yes|no
window size:	    20	    10-80
nonlinearity a:  relu    tanh|relu|no   # Nonlinearity used in feedforward attention type

entity library:      no      yes|no
similarity type:    cos     cos|dot
share weights:     yes      yes|no      # Whether to share weights between entity library and speaker embedding.
